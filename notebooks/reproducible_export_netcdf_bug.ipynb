{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import climakitae as ck \n",
    "from climakitae.core.data_interface import (\n",
    "    get_data_options, \n",
    "    get_subsetting_options, \n",
    "    get_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_riverside = get_data(\n",
    "    variable = \"Precipitation (total)\", \n",
    "    downscaling_method = \"Statistical\", \n",
    "    resolution = \"3 km\", \n",
    "    timescale = \"monthly\", \n",
    "    cached_area = \"Riverside County\", \n",
    "    approach = \"Warming Level\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting specified data to NetCDF...\n",
      "Saving file locally with compression...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "No conversion path for dtype: dtype('<U4')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mck\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprecip_riverside\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mriverside_annual_sum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNetCDF\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/climakitae/core/data_export.py:793\u001b[39m, in \u001b[36mexport\u001b[39m\u001b[34m(data, filename, format, mode)\u001b[39m\n\u001b[32m    789\u001b[39m \u001b[38;5;66;03m# now here is where exporting actually begins\u001b[39;00m\n\u001b[32m    790\u001b[39m \u001b[38;5;66;03m# we will have different functions for each file type\u001b[39;00m\n\u001b[32m    791\u001b[39m \u001b[38;5;66;03m# to keep things clean-ish\u001b[39;00m\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnetcdf\u001b[39m\u001b[33m\"\u001b[39m == req_format:\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m     \u001b[43m_export_to_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcsv\u001b[39m\u001b[33m\"\u001b[39m == req_format:\n\u001b[32m    795\u001b[39m     _export_to_csv(data, save_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/climakitae/core/data_export.py:301\u001b[39m, in \u001b[36m_export_to_netcdf\u001b[39m\u001b[34m(data, save_name, mode)\u001b[39m\n\u001b[32m    293\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m    294\u001b[39m             (\n\u001b[32m    295\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m exists. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    298\u001b[39m             )\n\u001b[32m    299\u001b[39m         )\n\u001b[32m    300\u001b[39m     encoding = _fillvalue_encoding(_data) | _compression_encoding(_data)\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m     \u001b[43m_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mh5netcdf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    303\u001b[39m         (\n\u001b[32m    304\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSaved! You can find your file in the panel to the left\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    305\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m and download to your local machine from there.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    306\u001b[39m         )\n\u001b[32m    307\u001b[39m     )\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/xarray/core/dataset.py:2372\u001b[39m, in \u001b[36mDataset.to_netcdf\u001b[39m\u001b[34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf, auto_complex)\u001b[39m\n\u001b[32m   2369\u001b[39m     encoding = {}\n\u001b[32m   2370\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxarray\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[32m-> \u001b[39m\u001b[32m2372\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[32m   2373\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2376\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2380\u001b[39m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmultifile\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2383\u001b[39m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2385\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/xarray/backends/api.py:1873\u001b[39m, in \u001b[36mto_netcdf\u001b[39m\u001b[34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf, auto_complex)\u001b[39m\n\u001b[32m   1868\u001b[39m \u001b[38;5;66;03m# TODO: figure out how to refactor this logic (here and in save_mfdataset)\u001b[39;00m\n\u001b[32m   1869\u001b[39m \u001b[38;5;66;03m# to avoid this mess of conditionals\u001b[39;00m\n\u001b[32m   1870\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1871\u001b[39m     \u001b[38;5;66;03m# TODO: allow this work (setting up the file for writing array data)\u001b[39;00m\n\u001b[32m   1872\u001b[39m     \u001b[38;5;66;03m# to be parallelized with dask\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1873\u001b[39m     \u001b[43mdump_to_store\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[43munlimited_dims\u001b[49m\n\u001b[32m   1875\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1876\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m autoclose:\n\u001b[32m   1877\u001b[39m         store.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/xarray/backends/api.py:1920\u001b[39m, in \u001b[36mdump_to_store\u001b[39m\u001b[34m(dataset, store, writer, encoder, encoding, unlimited_dims)\u001b[39m\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m encoder:\n\u001b[32m   1918\u001b[39m     variables, attrs = encoder(variables, attrs)\n\u001b[32m-> \u001b[39m\u001b[32m1920\u001b[39m \u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_encoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/xarray/backends/common.py:451\u001b[39m, in \u001b[36mAbstractWritableDataStore.store\u001b[39m\u001b[34m(self, variables, attributes, check_encoding_set, writer, unlimited_dims)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28mself\u001b[39m.set_attributes(attributes)\n\u001b[32m    450\u001b[39m \u001b[38;5;28mself\u001b[39m.set_dimensions(variables, unlimited_dims=unlimited_dims)\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mset_variables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_encoding_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[43munlimited_dims\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/xarray/backends/common.py:489\u001b[39m, in \u001b[36mAbstractWritableDataStore.set_variables\u001b[39m\u001b[34m(self, variables, check_encoding_set, writer, unlimited_dims)\u001b[39m\n\u001b[32m    487\u001b[39m name = _encode_variable_name(vn)\n\u001b[32m    488\u001b[39m check = vn \u001b[38;5;129;01min\u001b[39;00m check_encoding_set\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m target, source = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_variable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[43munlimited_dims\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m writer.add(source, target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/xarray/backends/h5netcdf_.py:363\u001b[39m, in \u001b[36mH5NetCDFStore.prepare_variable\u001b[39m\u001b[34m(self, name, variable, check_encoding, unlimited_dims)\u001b[39m\n\u001b[32m    360\u001b[39m     nc4_var = \u001b[38;5;28mself\u001b[39m.ds[name]\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m attrs.items():\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[43mnc4_var\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m = v\n\u001b[32m    365\u001b[39m target = H5NetCDFArrayWrapper(name, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m target, variable.data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/h5netcdf/attrs.py:86\u001b[39m, in \u001b[36mAttributes.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m     83\u001b[39m     dtype = np.asarray(value).dtype\n\u001b[32m     85\u001b[39m \u001b[38;5;28mself\u001b[39m._check_dtype(dtype)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_h5attrs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m = value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:54\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:55\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/h5py/_hl/attrs.py:104\u001b[39m, in \u001b[36mAttributeManager.__setitem__\u001b[39m\u001b[34m(self, name, value)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;129m@with_phil\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value):\n\u001b[32m     98\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" Set a new attribute, overwriting any existing attribute.\u001b[39;00m\n\u001b[32m     99\u001b[39m \n\u001b[32m    100\u001b[39m \u001b[33;03m    The type and shape of the attribute are determined from the data.  To\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03m    use a specific type or shape, or to preserve the type of an attribute,\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[33;03m    use the methods create() and modify().\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/h5py/_hl/attrs.py:182\u001b[39m, in \u001b[36mAttributeManager.create\u001b[39m\u001b[34m(self, name, data, shape, dtype)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;66;03m# Make HDF5 datatype and dataspace for the H5A calls\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_htype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     htype = \u001b[43mh5t\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpy_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogical\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m     htype2 = h5t.py_create(original_dtype)  \u001b[38;5;66;03m# Must be bit-for-bit representation rather than logical\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5t.pyx:1669\u001b[39m, in \u001b[36mh5py.h5t.py_create\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5t.pyx:1693\u001b[39m, in \u001b[36mh5py.h5t.py_create\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5t.pyx:1759\u001b[39m, in \u001b[36mh5py.h5t.py_create\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: No conversion path for dtype: dtype('<U4')"
     ]
    }
   ],
   "source": [
    "ck.export(precip_riverside, filename=\"riverside_annual_sum\", format=\"NetCDF\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
